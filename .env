# Multi-Model LLM System Configuration
# This file contains all configuration variables for the project

# DATA PATHS
SLEEP_DATA_PATH=src/data/training_qna_sleep.json
CAR_DATA_PATH=src/data/training_qna_car.json

# MODEL CONFIGURATION
GEN_BASE_MODEL=TinyLlama/TinyLlama-1.1B-Chat-v1.0

# API CONFIGURATION
API_HOST=0.0.0.0
API_PORT=8080
API_WORKERS=4

# LOGGING CONFIGURATION
LOG_LEVEL=INFO

# SECURITY CONFIGURATION
SECRET_KEY=your-secret-key-change-in-production
ALLOWED_ORIGINS=*

# ROUTER CONFIGURATION
ROUTER_CONFIDENCE_THRESHOLD=0.7
ROUTER_FALLBACK_THRESHOLD=0.5

# INFERENCE CONFIGURATION
DEFAULT_MAX_LENGTH=256
MAX_QUERY_LENGTH=1000
MIN_QUERY_LENGTH=3

# MODEL PATHS
SLEEP_MODEL_PATH=models/sleep_model
CAR_MODEL_PATH=models/car_model

# TRAINING CONFIGURATION
TRAINING_EPOCHS=3
TRAINING_LEARNING_RATE=5e-5
TRAINING_BATCH_SIZE=2
TRAINING_MAX_LENGTH=128
TRAINING_LOGGING_STEPS=10
TRAINING_SAVE_STEPS=100
TRAINING_EVAL_STEPS=100
TRAINING_SAVE_TOTAL_LIMIT=3

# EVALUATION CONFIGURATION
EVAL_OUTPUT_DIR=evaluation_results
EVAL_RESULTS_FILE=evaluation_results.json
