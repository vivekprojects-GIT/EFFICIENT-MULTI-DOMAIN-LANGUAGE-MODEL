{
  "adapter_path": "models/car_model",
  "batch_size": 2,
  "config": null,
  "data": "models/car_model",
  "fine_tune_type": "lora",
  "grad_checkpoint": true,
  "iters": 50,
  "learning_rate": 0.0001,
  "lora_parameters": {
    "rank": 8,
    "dropout": 0.0,
    "scale": 20.0
  },
  "lr_schedule": null,
  "mask_prompt": false,
  "max_seq_length": 256,
  "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
  "num_layers": 16,
  "optimizer": "adam",
  "optimizer_config": {
    "adam": {},
    "adamw": {},
    "muon": {},
    "sgd": {},
    "adafactor": {}
  },
  "project_name": null,
  "report_to": null,
  "resume_adapter_file": null,
  "save_every": 10,
  "seed": 42,
  "steps_per_eval": 200,
  "steps_per_report": 10,
  "test": false,
  "test_batches": 500,
  "train": true,
  "val_batches": 1,
  "wandb": null,
  "base_model_name_or_path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
  "model_type": "llama",
  "task_type": "CAUSAL_LM",
  "peft_type": "LORA",
  "lora_alpha": 32,
  "lora_dropout": 0.1,
  "lora_r": 16,
  "target_modules": [
    "q_proj",
    "v_proj",
    "k_proj",
    "o_proj"
  ],
  "bias": "none",
  "inference_mode": true
}